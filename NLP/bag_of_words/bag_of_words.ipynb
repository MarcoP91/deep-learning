{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with Bag of Words\n",
    "\n",
    "Dataset: spam-ham phone text dataset: https://archive.ics.uci.edu/ml/datasets/SMS+Spam+Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import os\n",
    "import numpy as np\n",
    "import csv\n",
    "import string\n",
    "import requests\n",
    "import io\n",
    "from zipfile import ZipFile\n",
    "from tensorflow.contrib import learn\n",
    "from tensorflow.python.framework import ops\n",
    "ops.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start the graph session\n",
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading/ reading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if the data file is saved, then do not download it again\n",
    "save_file_name = os.path.join('temp', 'temp_spam_data.csv')\n",
    "\n",
    "if not os.path.exists('temp'):\n",
    "    os.makedirs('temp')\n",
    "    \n",
    "if os.path.isfile(save_file_name):\n",
    "    # if the file exists, just read its\n",
    "    text_data = []\n",
    "    with open(save_file_name, 'r') as temp_output_file:\n",
    "        reader = csv.reader(temp_output_file)\n",
    "        for row in reader:\n",
    "            text_data.append(row)\n",
    "            \n",
    "else:\n",
    "    # if it does not, download it\n",
    "    zip_url = 'http://archive.ics.uci.edu/ml/machine-learning-databases/00228/smsspamcollection.zip'\n",
    "    r = requests.get(zip_url)\n",
    "    z = ZipFile(io.BytesIO(r.content))\n",
    "    file = z.read('SMSSpamCollection')\n",
    "    # Format Data\n",
    "    text_data = file.decode()\n",
    "    text_data = text_data.encode('ascii', errors='ignore')\n",
    "    text_data = text_data.decode().split('\\n')\n",
    "    text_data = [x.split('\\t') for x in text_data if len(x) > 1]\n",
    "    \n",
    "    # write to csv\n",
    "    with open(save_file_name, 'w') as temp_output_file:\n",
    "        writer = csv.writer(temp_output_file)\n",
    "        writer.writerows(text_data)\n",
    "        \n",
    "texts = [x[1] for x in text_data]\n",
    "target = [x[0] for x in text_data]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spam is 1, ham is 0\n",
    "target = [1 if x=='spam' else 0 for x in target]\n",
    "\n",
    "# Lower case\n",
    "texts = [x.lower() for x in texts]\n",
    "\n",
    "# Remove punctuation\n",
    "texts = [''.join(c for c in x if c not in string.punctuation) for x in texts]\n",
    "\n",
    "# Remove numbers\n",
    "texts = [''.join(c for c in x if c not in '0123456789') for x in texts]\n",
    "\n",
    "# trim extra whitespace\n",
    "texts = [' '.join(x.split()) for x in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# what are the sentences sizes?\n",
    "text_lengths = [len(x.split()) for x in texts]\n",
    "text_lengths = [x for x in text_lengths if x < 50]\n",
    "plt.hist(text_lengths, bins=25)\n",
    "plt.title('Histogram of text lengths')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choosing 25 as max text word, and filter out words that do not appear at least 3 times\n",
    "sentence_size = 25\n",
    "min_word_freq = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8165"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TensorFlow has a built-in processing tool for determining vocabulary embedding, \n",
    "#called VocabularyProcessor(), under the learn.preprocessing library:\n",
    "\n",
    "vocab_processor = learn.preprocessing.VocabularyProcessor(sentence_size, min_frequency= min_word_freq)\n",
    "\n",
    "# transforms the document using the vocabulary\n",
    "transformed_texts = np.array([x for x in vocab_processor.transform(texts)])\n",
    "\n",
    "# how many unique words do we have?\n",
    "embedding_size = len(np.unique(transformed_texts))\n",
    "embedding_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take 80% of the data indices\n",
    "train_indices = np.random.choice(len(texts), round(len(texts)*0.8), replace = False)\n",
    "# and all the rest of the indices\n",
    "test_indices = np.array(list(set(range(len(texts))) - set(train_indices)))\n",
    "\n",
    "texts_train = [x for ix, x in enumerate(texts) if ix in train_indices]\n",
    "texts_test = [x for ix, x in enumerate(texts) if ix in test_indices]\n",
    "\n",
    "target_train = [x for ix, x in enumerate(target) if ix in train_indices]\n",
    "target_test = [x for ix, x in enumerate(target) if ix in test_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creation of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since the indices will be translated into a one-hot encoded vector, \n",
    "# an identity matrix of [embedding_size] will be created. Iw will be used to look up the \n",
    "# sparse vector for each word and add them together for a sparse sentence word.\n",
    "\n",
    "identity_mat = tf.diag(tf.ones(shape= [embedding_size]))\n",
    "\n",
    "# The model will use logistic regression. \n",
    "A = tf.Variable(tf.random_normal(shape=[embedding_size, 1]))\n",
    "b = tf.Variable(tf.random_normal(shape=[1,1]))\n",
    "\n",
    "# placeholders. The X_data has type int because it will look up the row index of the\n",
    "# identity matrix\n",
    "\n",
    "x_data = tf.placeholder(shape=[sentence_size], dtype=tf.int32)\n",
    "y_target = tf.placeholder(shape=[1,1], dtype= tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next,  the text-word embedding lookup with the prior identity matrix. It will map the indices of the \n",
    "words in the sentence to the one-hot-encoded vectors of our identity matrix.\n",
    "\n",
    "The logistic regression will use the counts of the words as the input. The counts are created by summing the embedding output across the rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text- vocab embedding\n",
    "# x_embed will have dimansions (1, embedding_size)\n",
    "x_embed = tf.nn.embedding_lookup(identity_mat, x_data)\n",
    "# sum across rows\n",
    "x_col_sums = tf.reduce_sum(x_embed,0)\n",
    "\n",
    "# Declare model operations\n",
    "# expand the input dimensions, so that linear regression can be performed on it\n",
    "x_col_sums_2D = tf.expand_dims(x_col_sums, 0)\n",
    "model_output = tf.add(tf.matmul(x_col_sums_2D, A), b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare loss function (Cross Entropy loss)\n",
    "loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits= model_output, labels= y_target))\n",
    "\n",
    "# Prediction\n",
    "prediction = tf.sigmoid(model_output)\n",
    "\n",
    "# optimizer\n",
    "my_opt = tf.train.GradientDescentOptimizer(0.001)\n",
    "train_step = my_opt.minimize(loss)\n",
    "\n",
    "# Initialize variables\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training Over 4459 Sentences.\n",
      "Training Observation #10: Loss = 6.076842\n",
      "Training Observation #20: Loss = 0.005313548\n",
      "Training Observation #30: Loss = 0.0031701033\n",
      "Training Observation #40: Loss = 1.2173673e-05\n",
      "Training Observation #50: Loss = 0.007795104\n",
      "Training Observation #60: Loss = 9.60471e-07\n",
      "Training Observation #70: Loss = 0.009681831\n",
      "Training Observation #80: Loss = 7.8934494e-07\n",
      "Training Observation #90: Loss = 0.036967747\n",
      "Training Observation #100: Loss = 1.2152709\n",
      "Training Observation #110: Loss = 7.000991e-06\n",
      "Training Observation #120: Loss = 0.0007126354\n",
      "Training Observation #130: Loss = 0.00063767604\n",
      "Training Observation #140: Loss = 13.880115\n",
      "Training Observation #150: Loss = 3.5934556\n",
      "Training Observation #160: Loss = 1.1005588\n",
      "Training Observation #170: Loss = 0.00014791511\n",
      "Training Observation #180: Loss = 0.00013202426\n",
      "Training Observation #190: Loss = 0.027400695\n",
      "Training Observation #200: Loss = 1.9420666e-05\n",
      "Training Observation #210: Loss = 0.43925306\n",
      "Training Observation #220: Loss = 0.32666647\n",
      "Training Observation #230: Loss = 0.0003475153\n",
      "Training Observation #240: Loss = 12.52478\n",
      "Training Observation #250: Loss = 1.7885386e-05\n",
      "Training Observation #260: Loss = 7.7614264\n",
      "Training Observation #270: Loss = 0.058756627\n",
      "Training Observation #280: Loss = 3.8621306e-06\n",
      "Training Observation #290: Loss = 2.673627e-05\n",
      "Training Observation #300: Loss = 6.6605067\n",
      "Training Observation #310: Loss = 1.030408e-05\n",
      "Training Observation #320: Loss = 0.0032155775\n",
      "Training Observation #330: Loss = 5.0665272e-05\n",
      "Training Observation #340: Loss = 3.4411164e-06\n",
      "Training Observation #350: Loss = 0.0005582492\n",
      "Training Observation #360: Loss = 0.00022642265\n",
      "Training Observation #370: Loss = 2.6080244e-05\n",
      "Training Observation #380: Loss = 0.09100478\n",
      "Training Observation #390: Loss = 0.008107388\n",
      "Training Observation #400: Loss = 0.00020788626\n",
      "Training Observation #410: Loss = 0.0001594963\n",
      "Training Observation #420: Loss = 0.8260803\n",
      "Training Observation #430: Loss = 1.8817598e-05\n",
      "Training Observation #440: Loss = 0.00013326322\n",
      "Training Observation #450: Loss = 0.017816814\n",
      "Training Observation #460: Loss = 0.9349352\n",
      "Training Observation #470: Loss = 5.608425\n",
      "Training Observation #480: Loss = 0.002340185\n",
      "Training Observation #490: Loss = 0.0032238238\n",
      "Training Observation #500: Loss = 0.5430585\n",
      "Training Observation #510: Loss = 0.0106952945\n",
      "Training Observation #520: Loss = 0.3138044\n",
      "Training Observation #530: Loss = 0.00028816517\n",
      "Training Observation #540: Loss = 0.009137517\n",
      "Training Observation #550: Loss = 0.00065688766\n",
      "Training Observation #560: Loss = 8.673734\n",
      "Training Observation #570: Loss = 0.0016584359\n",
      "Training Observation #580: Loss = 0.023671992\n",
      "Training Observation #590: Loss = 4.0226173\n",
      "Training Observation #600: Loss = 4.502286\n",
      "Training Observation #610: Loss = 0.0018474502\n",
      "Training Observation #620: Loss = 9.119983\n",
      "Training Observation #630: Loss = 0.072679415\n",
      "Training Observation #640: Loss = 0.004315136\n",
      "Training Observation #650: Loss = 0.18191645\n",
      "Training Observation #660: Loss = 0.00013076089\n",
      "Training Observation #670: Loss = 0.10648631\n",
      "Training Observation #680: Loss = 0.1668808\n",
      "Training Observation #690: Loss = 8.487143\n",
      "Training Observation #700: Loss = 0.0008582157\n",
      "Training Observation #710: Loss = 0.0012592899\n",
      "Training Observation #720: Loss = 0.050972912\n",
      "Training Observation #730: Loss = 0.43838078\n",
      "Training Observation #740: Loss = 0.093897946\n",
      "Training Observation #750: Loss = 0.00017510407\n",
      "Training Observation #760: Loss = 2.0434163e-05\n",
      "Training Observation #770: Loss = 0.00013454512\n",
      "Training Observation #780: Loss = 0.000888065\n",
      "Training Observation #790: Loss = 4.1203513\n",
      "Training Observation #800: Loss = 0.008341948\n",
      "Training Observation #810: Loss = 0.0007066572\n",
      "Training Observation #820: Loss = 0.0010640945\n",
      "Training Observation #830: Loss = 0.41971937\n",
      "Training Observation #840: Loss = 0.00046445275\n",
      "Training Observation #850: Loss = 0.0029334077\n",
      "Training Observation #860: Loss = 0.22344598\n",
      "Training Observation #870: Loss = 0.0026204493\n",
      "Training Observation #880: Loss = 0.07329607\n",
      "Training Observation #890: Loss = 0.002489178\n",
      "Training Observation #900: Loss = 0.0024651517\n",
      "Training Observation #910: Loss = 0.001181363\n",
      "Training Observation #920: Loss = 0.025683794\n",
      "Training Observation #930: Loss = 0.18152745\n",
      "Training Observation #940: Loss = 0.011099832\n",
      "Training Observation #950: Loss = 8.597319e-05\n",
      "Training Observation #960: Loss = 0.0017560886\n",
      "Training Observation #970: Loss = 0.00016008706\n",
      "Training Observation #980: Loss = 0.0001837538\n",
      "Training Observation #990: Loss = 2.596576\n",
      "Training Observation #1000: Loss = 0.7837226\n",
      "Training Observation #1010: Loss = 0.83122873\n",
      "Training Observation #1020: Loss = 0.0057398677\n",
      "Training Observation #1030: Loss = 0.00019263999\n",
      "Training Observation #1040: Loss = 0.0035555817\n",
      "Training Observation #1050: Loss = 0.04961377\n",
      "Training Observation #1060: Loss = 4.568276e-05\n",
      "Training Observation #1070: Loss = 0.00014294684\n",
      "Training Observation #1080: Loss = 0.0022158436\n",
      "Training Observation #1090: Loss = 5.450712\n",
      "Training Observation #1100: Loss = 1.916946\n",
      "Training Observation #1110: Loss = 0.0005440034\n",
      "Training Observation #1120: Loss = 0.7271589\n",
      "Training Observation #1130: Loss = 0.00034824855\n",
      "Training Observation #1140: Loss = 0.33709273\n",
      "Training Observation #1150: Loss = 1.6641526\n",
      "Training Observation #1160: Loss = 0.00016850106\n",
      "Training Observation #1170: Loss = 0.00015609794\n",
      "Training Observation #1180: Loss = 0.00015048085\n",
      "Training Observation #1190: Loss = 0.000677226\n",
      "Training Observation #1200: Loss = 2.6350355\n",
      "Training Observation #1210: Loss = 0.0034187215\n",
      "Training Observation #1220: Loss = 0.2707519\n",
      "Training Observation #1230: Loss = 7.7544208\n",
      "Training Observation #1240: Loss = 0.0007457495\n",
      "Training Observation #1250: Loss = 4.9586945\n",
      "Training Observation #1260: Loss = 9.459599e-05\n",
      "Training Observation #1270: Loss = 2.1307696e-05\n",
      "Training Observation #1280: Loss = 0.005543068\n",
      "Training Observation #1290: Loss = 0.00011825882\n",
      "Training Observation #1300: Loss = 8.588371\n",
      "Training Observation #1310: Loss = 0.0013439282\n",
      "Training Observation #1320: Loss = 0.0005797637\n",
      "Training Observation #1330: Loss = 0.07459661\n",
      "Training Observation #1340: Loss = 0.0005989811\n",
      "Training Observation #1350: Loss = 0.3433206\n",
      "Training Observation #1360: Loss = 0.003912845\n",
      "Training Observation #1370: Loss = 0.0045117205\n",
      "Training Observation #1380: Loss = 0.00017878723\n",
      "Training Observation #1390: Loss = 1.9996979\n",
      "Training Observation #1400: Loss = 0.48993263\n",
      "Training Observation #1410: Loss = 0.0021885727\n",
      "Training Observation #1420: Loss = 2.3197088\n",
      "Training Observation #1430: Loss = 0.00083711644\n",
      "Training Observation #1440: Loss = 0.39310873\n",
      "Training Observation #1450: Loss = 0.012139581\n",
      "Training Observation #1460: Loss = 0.014741439\n",
      "Training Observation #1470: Loss = 3.8460705\n",
      "Training Observation #1480: Loss = 0.00021020678\n",
      "Training Observation #1490: Loss = 1.54079\n",
      "Training Observation #1500: Loss = 0.038494337\n",
      "Training Observation #1510: Loss = 8.52892\n",
      "Training Observation #1520: Loss = 0.03718705\n",
      "Training Observation #1530: Loss = 4.2889\n",
      "Training Observation #1540: Loss = 0.03805418\n",
      "Training Observation #1550: Loss = 7.814783e-05\n",
      "Training Observation #1560: Loss = 0.17231667\n",
      "Training Observation #1570: Loss = 3.0240488\n",
      "Training Observation #1580: Loss = 1.1420121\n",
      "Training Observation #1590: Loss = 0.5729858\n",
      "Training Observation #1600: Loss = 3.6468706\n",
      "Training Observation #1610: Loss = 0.000104946106\n",
      "Training Observation #1620: Loss = 0.01218472\n",
      "Training Observation #1630: Loss = 0.0006888804\n",
      "Training Observation #1640: Loss = 0.0001709252\n",
      "Training Observation #1650: Loss = 0.000185973\n",
      "Training Observation #1660: Loss = 8.132625\n",
      "Training Observation #1670: Loss = 0.904887\n",
      "Training Observation #1680: Loss = 6.7106843\n",
      "Training Observation #1690: Loss = 0.6668651\n",
      "Training Observation #1700: Loss = 3.1469152\n",
      "Training Observation #1710: Loss = 2.482213e-05\n",
      "Training Observation #1720: Loss = 7.5304203\n",
      "Training Observation #1730: Loss = 0.00024858993\n",
      "Training Observation #1740: Loss = 0.0015675873\n",
      "Training Observation #1750: Loss = 0.00013903527\n",
      "Training Observation #1760: Loss = 0.01880896\n",
      "Training Observation #1770: Loss = 0.0061805523\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Observation #1780: Loss = 4.3576998e-05\n",
      "Training Observation #1790: Loss = 0.0024586115\n",
      "Training Observation #1800: Loss = 0.00068637583\n",
      "Training Observation #1810: Loss = 2.4238567\n",
      "Training Observation #1820: Loss = 0.0035375203\n",
      "Training Observation #1830: Loss = 6.7751927\n",
      "Training Observation #1840: Loss = 0.0068407096\n",
      "Training Observation #1850: Loss = 4.7718225\n",
      "Training Observation #1860: Loss = 0.0007661102\n",
      "Training Observation #1870: Loss = 0.4855163\n",
      "Training Observation #1880: Loss = 0.0018864516\n",
      "Training Observation #1890: Loss = 5.636088\n",
      "Training Observation #1900: Loss = 0.0002275395\n",
      "Training Observation #1910: Loss = 5.9910573e-05\n",
      "Training Observation #1920: Loss = 0.0005816425\n",
      "Training Observation #1930: Loss = 4.9207905e-05\n",
      "Training Observation #1940: Loss = 0.0033736168\n",
      "Training Observation #1950: Loss = 4.221162\n",
      "Training Observation #1960: Loss = 6.2364765e-05\n",
      "Training Observation #1970: Loss = 0.005042029\n",
      "Training Observation #1980: Loss = 0.0005926026\n",
      "Training Observation #1990: Loss = 0.0015775698\n",
      "Training Observation #2000: Loss = 0.001965795\n",
      "Training Observation #2010: Loss = 7.251368e-05\n",
      "Training Observation #2020: Loss = 0.00065991684\n",
      "Training Observation #2030: Loss = 8.91654e-07\n",
      "Training Observation #2040: Loss = 0.00030080866\n",
      "Training Observation #2050: Loss = 0.0011992701\n",
      "Training Observation #2060: Loss = 0.017150631\n",
      "Training Observation #2070: Loss = 0.06328831\n",
      "Training Observation #2080: Loss = 0.0069106263\n",
      "Training Observation #2090: Loss = 0.63943136\n",
      "Training Observation #2100: Loss = 0.0034164113\n",
      "Training Observation #2110: Loss = 0.00059847906\n",
      "Training Observation #2120: Loss = 0.059963502\n",
      "Training Observation #2130: Loss = 0.00050040695\n",
      "Training Observation #2140: Loss = 0.0014386781\n",
      "Training Observation #2150: Loss = 0.2066313\n",
      "Training Observation #2160: Loss = 0.4001158\n",
      "Training Observation #2170: Loss = 0.009143755\n",
      "Training Observation #2180: Loss = 8.580675e-05\n",
      "Training Observation #2190: Loss = 0.05894245\n",
      "Training Observation #2200: Loss = 0.033319008\n",
      "Training Observation #2210: Loss = 0.05122937\n",
      "Training Observation #2220: Loss = 2.532522\n",
      "Training Observation #2230: Loss = 0.0002862364\n",
      "Training Observation #2240: Loss = 0.00055083836\n",
      "Training Observation #2250: Loss = 8.6875894e-05\n",
      "Training Observation #2260: Loss = 0.015957667\n",
      "Training Observation #2270: Loss = 6.4806234e-05\n",
      "Training Observation #2280: Loss = 0.0005599573\n",
      "Training Observation #2290: Loss = 2.8957058e-06\n",
      "Training Observation #2300: Loss = 0.0032846257\n",
      "Training Observation #2310: Loss = 0.0021090482\n",
      "Training Observation #2320: Loss = 0.00033603364\n",
      "Training Observation #2330: Loss = 0.5959714\n",
      "Training Observation #2340: Loss = 0.011191132\n",
      "Training Observation #2350: Loss = 0.15633525\n",
      "Training Observation #2360: Loss = 1.461093e-06\n",
      "Training Observation #2370: Loss = 0.00010998513\n",
      "Training Observation #2380: Loss = 0.06754468\n",
      "Training Observation #2390: Loss = 0.003542002\n",
      "Training Observation #2400: Loss = 0.09169306\n",
      "Training Observation #2410: Loss = 0.0025021164\n",
      "Training Observation #2420: Loss = 0.0019569218\n",
      "Training Observation #2430: Loss = 0.088617444\n",
      "Training Observation #2440: Loss = 2.6972356\n",
      "Training Observation #2450: Loss = 3.542678\n",
      "Training Observation #2460: Loss = 0.0024364723\n",
      "Training Observation #2470: Loss = 3.2855165e-05\n",
      "Training Observation #2480: Loss = 0.03943875\n",
      "Training Observation #2490: Loss = 2.4192343\n",
      "Training Observation #2500: Loss = 0.0006890646\n",
      "Training Observation #2510: Loss = 0.0002962672\n",
      "Training Observation #2520: Loss = 0.021193605\n",
      "Training Observation #2530: Loss = 3.3508735\n",
      "Training Observation #2540: Loss = 0.0009100596\n",
      "Training Observation #2550: Loss = 0.016544761\n",
      "Training Observation #2560: Loss = 0.0001883321\n",
      "Training Observation #2570: Loss = 0.79154533\n",
      "Training Observation #2580: Loss = 0.00011876751\n",
      "Training Observation #2590: Loss = 0.0006125332\n",
      "Training Observation #2600: Loss = 0.007916491\n",
      "Training Observation #2610: Loss = 0.0010295806\n",
      "Training Observation #2620: Loss = 1.2141903e-05\n",
      "Training Observation #2630: Loss = 0.055359855\n",
      "Training Observation #2640: Loss = 0.08756641\n",
      "Training Observation #2650: Loss = 0.114758186\n",
      "Training Observation #2660: Loss = 0.00034917454\n",
      "Training Observation #2670: Loss = 0.00018857939\n",
      "Training Observation #2680: Loss = 0.0009544596\n",
      "Training Observation #2690: Loss = 0.010914118\n",
      "Training Observation #2700: Loss = 0.00056842726\n",
      "Training Observation #2710: Loss = 2.8820689\n",
      "Training Observation #2720: Loss = 3.8572514\n",
      "Training Observation #2730: Loss = 0.011050569\n",
      "Training Observation #2740: Loss = 5.0348008e-05\n",
      "Training Observation #2750: Loss = 3.7224357\n",
      "Training Observation #2760: Loss = 0.0050728144\n",
      "Training Observation #2770: Loss = 0.13621631\n",
      "Training Observation #2780: Loss = 4.2803793\n",
      "Training Observation #2790: Loss = 0.002138881\n",
      "Training Observation #2800: Loss = 0.8737169\n",
      "Training Observation #2810: Loss = 1.1732774\n",
      "Training Observation #2820: Loss = 8.038535e-05\n",
      "Training Observation #2830: Loss = 1.4953616e-05\n",
      "Training Observation #2840: Loss = 0.0003688188\n",
      "Training Observation #2850: Loss = 0.23449644\n",
      "Training Observation #2860: Loss = 0.0009201815\n",
      "Training Observation #2870: Loss = 0.00014667121\n",
      "Training Observation #2880: Loss = 0.080432534\n",
      "Training Observation #2890: Loss = 0.0001754872\n",
      "Training Observation #2900: Loss = 0.0015589851\n",
      "Training Observation #2910: Loss = 0.37273812\n",
      "Training Observation #2920: Loss = 0.0056233844\n",
      "Training Observation #2930: Loss = 6.57199\n",
      "Training Observation #2940: Loss = 0.00013303544\n",
      "Training Observation #2950: Loss = 0.0012235031\n",
      "Training Observation #2960: Loss = 0.0042686043\n",
      "Training Observation #2970: Loss = 0.00011398641\n",
      "Training Observation #2980: Loss = 0.099238604\n",
      "Training Observation #2990: Loss = 0.0014144072\n",
      "Training Observation #3000: Loss = 0.002677874\n",
      "Training Observation #3010: Loss = 0.09422577\n",
      "Training Observation #3020: Loss = 3.381781e-05\n",
      "Training Observation #3030: Loss = 0.003204617\n",
      "Training Observation #3040: Loss = 0.0009212101\n",
      "Training Observation #3050: Loss = 0.0014355056\n",
      "Training Observation #3060: Loss = 0.0020746316\n",
      "Training Observation #3070: Loss = 3.895643\n",
      "Training Observation #3080: Loss = 0.0006579318\n",
      "Training Observation #3090: Loss = 0.0004645823\n",
      "Training Observation #3100: Loss = 2.0285144\n",
      "Training Observation #3110: Loss = 0.00064799417\n",
      "Training Observation #3120: Loss = 3.2195217e-05\n",
      "Training Observation #3130: Loss = 4.2254496\n",
      "Training Observation #3140: Loss = 0.2150504\n",
      "Training Observation #3150: Loss = 0.0039549866\n",
      "Training Observation #3160: Loss = 0.098293915\n",
      "Training Observation #3170: Loss = 0.011123057\n",
      "Training Observation #3180: Loss = 0.012268847\n",
      "Training Observation #3190: Loss = 0.0013758704\n",
      "Training Observation #3200: Loss = 5.243536\n",
      "Training Observation #3210: Loss = 0.36035335\n",
      "Training Observation #3220: Loss = 0.00019600443\n",
      "Training Observation #3230: Loss = 0.31499723\n",
      "Training Observation #3240: Loss = 0.013107198\n",
      "Training Observation #3250: Loss = 0.0008991095\n",
      "Training Observation #3260: Loss = 0.05289374\n",
      "Training Observation #3270: Loss = 0.36145172\n",
      "Training Observation #3280: Loss = 0.00015761706\n",
      "Training Observation #3290: Loss = 8.736557e-05\n",
      "Training Observation #3300: Loss = 0.16322696\n",
      "Training Observation #3310: Loss = 3.290885\n",
      "Training Observation #3320: Loss = 0.0037357532\n",
      "Training Observation #3330: Loss = 0.044928633\n",
      "Training Observation #3340: Loss = 0.018933333\n",
      "Training Observation #3350: Loss = 0.0018920867\n",
      "Training Observation #3360: Loss = 0.0024224895\n",
      "Training Observation #3370: Loss = 0.0018939967\n",
      "Training Observation #3380: Loss = 0.0059267115\n",
      "Training Observation #3390: Loss = 0.00041341432\n",
      "Training Observation #3400: Loss = 8.5981555e-05\n",
      "Training Observation #3410: Loss = 2.3248081\n",
      "Training Observation #3420: Loss = 0.02445699\n",
      "Training Observation #3430: Loss = 0.0001887539\n",
      "Training Observation #3440: Loss = 1.5659187\n",
      "Training Observation #3450: Loss = 10.54277\n",
      "Training Observation #3460: Loss = 0.027326267\n",
      "Training Observation #3470: Loss = 0.08845979\n",
      "Training Observation #3480: Loss = 0.00420999\n",
      "Training Observation #3490: Loss = 0.020058008\n",
      "Training Observation #3500: Loss = 0.005498839\n",
      "Training Observation #3510: Loss = 0.55502784\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Observation #3520: Loss = 0.43395346\n",
      "Training Observation #3530: Loss = 4.61607\n",
      "Training Observation #3540: Loss = 5.8030997e-05\n",
      "Training Observation #3550: Loss = 0.0002697744\n",
      "Training Observation #3560: Loss = 0.004239654\n",
      "Training Observation #3570: Loss = 0.00014887184\n",
      "Training Observation #3580: Loss = 4.2762207e-05\n",
      "Training Observation #3590: Loss = 0.27428082\n",
      "Training Observation #3600: Loss = 0.85009575\n",
      "Training Observation #3610: Loss = 0.00038727472\n",
      "Training Observation #3620: Loss = 4.348058\n",
      "Training Observation #3630: Loss = 0.010096455\n",
      "Training Observation #3640: Loss = 1.4348035\n",
      "Training Observation #3650: Loss = 0.045249417\n",
      "Training Observation #3660: Loss = 0.0691248\n",
      "Training Observation #3670: Loss = 0.4990054\n",
      "Training Observation #3680: Loss = 0.087334804\n",
      "Training Observation #3690: Loss = 0.64136404\n",
      "Training Observation #3700: Loss = 0.010032798\n",
      "Training Observation #3710: Loss = 3.7458474e-05\n",
      "Training Observation #3720: Loss = 0.77698725\n",
      "Training Observation #3730: Loss = 0.0069245673\n",
      "Training Observation #3740: Loss = 0.0031052118\n",
      "Training Observation #3750: Loss = 0.060027573\n",
      "Training Observation #3760: Loss = 0.0070994394\n",
      "Training Observation #3770: Loss = 0.10728941\n",
      "Training Observation #3780: Loss = 0.00030475063\n",
      "Training Observation #3790: Loss = 0.00038153832\n",
      "Training Observation #3800: Loss = 0.0029989437\n",
      "Training Observation #3810: Loss = 0.00143176\n",
      "Training Observation #3820: Loss = 0.0006045311\n",
      "Training Observation #3830: Loss = 0.19228001\n",
      "Training Observation #3840: Loss = 0.079267055\n",
      "Training Observation #3850: Loss = 0.008439184\n",
      "Training Observation #3860: Loss = 0.0017693454\n",
      "Training Observation #3870: Loss = 0.0018780462\n",
      "Training Observation #3880: Loss = 0.1792674\n",
      "Training Observation #3890: Loss = 0.0006982202\n",
      "Training Observation #3900: Loss = 4.0175796\n",
      "Training Observation #3910: Loss = 1.3118528\n",
      "Training Observation #3920: Loss = 0.039466448\n",
      "Training Observation #3930: Loss = 0.021898217\n",
      "Training Observation #3940: Loss = 8.846411\n",
      "Training Observation #3950: Loss = 0.02936006\n",
      "Training Observation #3960: Loss = 0.7685699\n",
      "Training Observation #3970: Loss = 0.044045713\n",
      "Training Observation #3980: Loss = 8.81065\n",
      "Training Observation #3990: Loss = 4.0150055e-05\n",
      "Training Observation #4000: Loss = 3.7308278\n",
      "Training Observation #4010: Loss = 0.133906\n",
      "Training Observation #4020: Loss = 0.0008564545\n",
      "Training Observation #4030: Loss = 0.60266495\n",
      "Training Observation #4040: Loss = 0.03300877\n",
      "Training Observation #4050: Loss = 0.1312281\n",
      "Training Observation #4060: Loss = 0.00049814483\n",
      "Training Observation #4070: Loss = 0.2658824\n",
      "Training Observation #4080: Loss = 0.0007429189\n",
      "Training Observation #4090: Loss = 1.2080286\n",
      "Training Observation #4100: Loss = 0.05894317\n",
      "Training Observation #4110: Loss = 0.32958552\n",
      "Training Observation #4120: Loss = 2.5536704\n",
      "Training Observation #4130: Loss = 3.6189338e-06\n",
      "Training Observation #4140: Loss = 0.0009487405\n",
      "Training Observation #4150: Loss = 0.13677351\n",
      "Training Observation #4160: Loss = 7.319649e-05\n",
      "Training Observation #4170: Loss = 0.032613162\n",
      "Training Observation #4180: Loss = 0.0009008626\n",
      "Training Observation #4190: Loss = 0.02295963\n",
      "Training Observation #4200: Loss = 0.006230887\n",
      "Training Observation #4210: Loss = 0.023679806\n",
      "Training Observation #4220: Loss = 0.0012283005\n",
      "Training Observation #4230: Loss = 0.6445664\n",
      "Training Observation #4240: Loss = 0.00240174\n",
      "Training Observation #4250: Loss = 0.10175925\n",
      "Training Observation #4260: Loss = 0.48440465\n",
      "Training Observation #4270: Loss = 0.0037083516\n",
      "Training Observation #4280: Loss = 0.0018940239\n",
      "Training Observation #4290: Loss = 0.015926646\n",
      "Training Observation #4300: Loss = 0.00037441665\n",
      "Training Observation #4310: Loss = 0.059017826\n",
      "Training Observation #4320: Loss = 0.0004363961\n",
      "Training Observation #4330: Loss = 0.0024961904\n",
      "Training Observation #4340: Loss = 0.0026806118\n",
      "Training Observation #4350: Loss = 5.312012\n",
      "Training Observation #4360: Loss = 2.7983595e-05\n",
      "Training Observation #4370: Loss = 0.00011192488\n",
      "Training Observation #4380: Loss = 0.0014966715\n",
      "Training Observation #4390: Loss = 7.049768e-05\n",
      "Training Observation #4400: Loss = 0.03639514\n",
      "Training Observation #4410: Loss = 0.002638252\n",
      "Training Observation #4420: Loss = 0.0001760356\n",
      "Training Observation #4430: Loss = 3.8427937\n",
      "Training Observation #4440: Loss = 9.673883e-05\n",
      "Training Observation #4450: Loss = 0.08844627\n"
     ]
    }
   ],
   "source": [
    "print('Starting Training Over {} Sentences.'.format(len(texts_train)))\n",
    "loss_vec = []\n",
    "train_acc_all = []\n",
    "train_acc_avg = []\n",
    "for ix, t in enumerate(vocab_processor.fit_transform(texts_train)):\n",
    "    y_data = [[target_train[ix]]]\n",
    "    \n",
    "    sess.run(train_step, feed_dict={x_data: t, y_target: y_data})\n",
    "    temp_loss = sess.run(loss, feed_dict={x_data: t, y_target: y_data})\n",
    "    loss_vec.append(temp_loss)\n",
    "    \n",
    "    if (ix+1)%10==0:\n",
    "        print('Training Observation #' + str(ix+1) + ': Loss = ' + str(temp_loss))\n",
    "        \n",
    "        # Keep trailing average of past 50 observations accuracy\n",
    "        # Get prediction of single observation\n",
    "        temp_pred = sess.run(prediction, feed_dict={x_data:t, y_target:y_data})\n",
    "        # Get True/False if prediction is accurate\n",
    "        train_acc_temp = target_train[ix]==np.round(temp_pred)\n",
    "        train_acc_all.append(train_acc_temp)\n",
    "        if len(train_acc_all) >= 50:\n",
    "            train_acc_avg.append(np.mean(train_acc_all[-50:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting Test Set Accuracy For 1115 Sentences.\n",
      "Test Observation #50\n",
      "Test Observation #100\n",
      "Test Observation #150\n",
      "Test Observation #200\n",
      "Test Observation #250\n",
      "Test Observation #300\n",
      "Test Observation #350\n",
      "Test Observation #400\n",
      "Test Observation #450\n",
      "Test Observation #500\n",
      "Test Observation #550\n",
      "Test Observation #600\n",
      "Test Observation #650\n",
      "Test Observation #700\n",
      "Test Observation #750\n",
      "Test Observation #800\n",
      "Test Observation #850\n",
      "Test Observation #900\n",
      "Test Observation #950\n",
      "Test Observation #1000\n",
      "Test Observation #1050\n",
      "Test Observation #1100\n",
      "\n",
      "Overall Test Accuracy: 0.7838565022421524\n"
     ]
    }
   ],
   "source": [
    "# Get test set accuracy\n",
    "print('Getting Test Set Accuracy For {} Sentences.'.format(len(texts_test)))\n",
    "test_acc_all = []\n",
    "for ix, t in enumerate(vocab_processor.fit_transform(texts_test)):\n",
    "    y_data = [[target_test[ix]]]\n",
    "    \n",
    "    if (ix+1)%50==0:\n",
    "        print('Test Observation #' + str(ix+1))    \n",
    "    \n",
    "    # Keep trailing average of past 50 observations accuracy\n",
    "    # Get prediction of single observation\n",
    "    [[temp_pred]] = sess.run(prediction, feed_dict={x_data:t, y_target:y_data})\n",
    "    # Get True/False if prediction is accurate\n",
    "    test_acc_temp = target_test[ix]==np.round(temp_pred)\n",
    "    test_acc_all.append(test_acc_temp)\n",
    "\n",
    "print('\\nOverall Test Accuracy: {}'.format(np.mean(test_acc_all)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot training accuracy over time\n",
    "plt.plot(range(len(train_acc_avg)), train_acc_avg, 'k-', label='Train Accuracy')\n",
    "plt.title('Avg Training Acc Over Past 50 Iterations')\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Training Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is worthwhile to mention the motivation of limiting the sentence (or text) size. This is a common practice with bag of words because it limits the effect of text length on the prediction. <br>\n",
    "\n",
    "If there is a word, “meeting” for example, that is predictive of a text being ham (not spam), then a spam message might get through by putting in many occurrences of that word at the end. In fact, this is a common problem with imbalanced target data. Imbalanced data might occur in this situation, since spam may be hard to find and ham may be easy to find.\n",
    "\n",
    "\n",
    "Because of this fact, our vocabulary that we create might be heavily skewed toward words represented in the ham part of our data (more ham means more words are represented in ham than spam). If unlimited length of texts is allowed, then spammers might take advantage of this and create very long texts, which have a higher probability of triggering non-spam word factors in the logistic model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
