{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import imutils\n",
    "import math\n",
    "import glob\n",
    "from scipy import ndimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change this if you want the images to be showed during runtime\n",
    "SHOW_IMAGES = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not used.\n",
    "\n",
    "# def convert_to_3channels(img):\n",
    "    \n",
    "#     '''\n",
    "#     converts the image from single-channel grayscale into 3-channel BGR.\n",
    "#     '''\n",
    "#     gray = cv.cvtColor(img, cv.COLOR_GRAY2BGR)\n",
    "#     return gray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_wait_destroy_3d(winname, img):\n",
    "    \n",
    "    '''\n",
    "    shows a 3 channel image.\n",
    "    '''\n",
    "    s = 1\n",
    "    if SHOW_IMAGES:\n",
    "        rows,cols = img.shape[:2]\n",
    "        imS = cv.resize(img, (rows//4, cols//4))\n",
    "        #imS = img\n",
    "        cv.imshow(winname, imS)   \n",
    "        cv.moveWindow(winname, 300, 0)\n",
    "        cv.waitKey(0)\n",
    "        cv.destroyWindow(winname)\n",
    "        cv.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_wait_destroy_particular(winname, img):\n",
    "    \n",
    "    '''\n",
    "    shows small images.\n",
    "    '''\n",
    "    s =1 \n",
    "    if SHOW_IMAGES:\n",
    "        cv.imshow(winname, img)   \n",
    "        cv.moveWindow(winname, 300, 0)\n",
    "        cv.waitKey(0)\n",
    "        cv.destroyWindow(winname)\n",
    "        cv.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_wait_destroy(winname, img):\n",
    "    \n",
    "    '''\n",
    "    shows resized big images.\n",
    "    '''\n",
    "    s = 1\n",
    "    if SHOW_IMAGES:\n",
    "        rows,cols = img.shape\n",
    "        imS = cv.resize(img, (rows//4, cols//4))\n",
    "        cv.imshow(winname, imS)   \n",
    "        cv.moveWindow(winname, 300, 0)\n",
    "        cv.waitKey(0)\n",
    "        cv.destroyWindow(winname)\n",
    "        cv.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finds the horizontal and vertiac lines of the image. Not used.\n",
    "\n",
    "# def extract_lines(src, big = True):\n",
    "#     # [gray]\n",
    "#     # Transform source image to gray if it is not already\n",
    "#     if len(src.shape) != 2:\n",
    "#         gray = cv.cvtColor(src, cv.COLOR_BGR2GRAY)\n",
    "#     else:\n",
    "#         gray = src\n",
    "\n",
    "#     gray = cv.bitwise_not(gray)\n",
    "#     bw = cv.adaptiveThreshold(gray, 255, cv.ADAPTIVE_THRESH_MEAN_C, \\\n",
    "#                                 cv.THRESH_BINARY, 15, -2)\n",
    "\n",
    "#     horizontal = np.copy(bw)\n",
    "#     vertical = np.copy(bw)\n",
    "\n",
    "#     if big:\n",
    "#         denom = 30\n",
    "#     else:\n",
    "#         denom = 10\n",
    "    \n",
    "#     cols = horizontal.shape[1]\n",
    "#     horizontal_size = cols // denom\n",
    "#     # Create structure element for extracting horizontal lines through morphology operations\n",
    "#     horizontalStructure = cv.getStructuringElement(cv.MORPH_RECT, (horizontal_size, 1))\n",
    "#     # Apply morphology operations\n",
    "#     horizontal = cv.erode(horizontal, horizontalStructure)\n",
    "#     #show_wait_destroy_particular(\"horizontal\", horizontal)\n",
    "#     horizontal = cv.dilate(horizontal, horizontalStructure, iterations=4)\n",
    "    \n",
    "#     # [vert]\n",
    "#     # Specify size on vertical axis\n",
    "#     rows = vertical.shape[0]\n",
    "#     verticalsize = rows // denom\n",
    "#     # Create structure element for extracting vertical lines through morphology operations\n",
    "#     verticalStructure = cv.getStructuringElement(cv.MORPH_RECT, (1, verticalsize))\n",
    "#     # Apply morphology operations\n",
    "#     vertical = cv.erode(vertical, verticalStructure)\n",
    "#     #show_wait_destroy_particular(\"vertical\", vertical)\n",
    "#     vertical = cv.dilate(vertical, verticalStructure, iterations=4)\n",
    "\n",
    "    \n",
    "#     result = cv.addWeighted(vertical,1,horizontal,1,0)\n",
    "    \n",
    "#     #show_wait_destroy_particular('result', result)\n",
    "\n",
    "#     #res2 = cv.add(result, src)\n",
    "#     res2 = cv.inpaint(src,result,3,cv.INPAINT_TELEA)\n",
    "#     #show_wait_destroy_particular('result2', res2)\n",
    "#     return res2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_angle(img_before):\n",
    "    \n",
    "    '''\n",
    "    ind the angle at wich the image is rotated, and deskew the image\n",
    "    '''\n",
    "    show_wait_destroy('Image before deskewing', img_before)\n",
    "    img_gray = img_before\n",
    "    img_edges = cv.Canny(img_gray, 100, 100, apertureSize=3)\n",
    "    lines = cv.HoughLinesP(img_edges, 1, math.pi / 180.0, 100, minLineLength=600, maxLineGap=30)\n",
    "\n",
    "    angles = []\n",
    "\n",
    "    for x1, y1, x2, y2 in lines[:,0]:\n",
    "        #cv.line(img_before, (x1, y1), (x2, y2), 0, 1)\n",
    "        angle = math.degrees(math.atan2(y2 - y1, x2 - x1))\n",
    "        angles.append(angle)\n",
    "\n",
    "    median_angle = np.median(angles)\n",
    "    img_rotated = ndimage.rotate(img_before, median_angle)\n",
    "    show_wait_destroy(\"Image after deskewing\", img_rotated) \n",
    "    #print(\"Angle is {}\".format(median_angle))\n",
    "    return img_rotated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_bounding_boxes_fixed(img, maxLoc, w, h,scaled=0, ratio = 1):\n",
    "    \n",
    "    '''\n",
    "    finds the bounding boxes for license, vin and date\n",
    "    '''\n",
    "\n",
    "    top_left = maxLoc\n",
    "    \n",
    "    license_hieight = int(h * 1.4 * ratio) + scaled\n",
    "    license_width = int(w * 5.2 * ratio) + scaled\n",
    "    \n",
    "    # the license box could be out of bounds on the left\n",
    "    top_left_license_w = int(top_left[0]  - (w *2.4*ratio)) - scaled//2\n",
    "    if top_left_license_w < 0:\n",
    "        top_left_license_w = 0\n",
    "    top_left_license_h = int(top_left[1] + (h * 4.7*ratio)) - scaled//2\n",
    "    if top_left_license_h < 0:\n",
    "        top_left_license_h = 0\n",
    "        \n",
    "    top_left_license = (top_left_license_w, top_left_license_h)\n",
    "    bottom_right_license = (top_left_license[0] + license_width, top_left_license[1] + license_hieight)\n",
    "\n",
    "    date_hieight = int(h * 1.3 * ratio) + scaled\n",
    "    date_width = int(w * 3.5 * ratio) + scaled\n",
    "    \n",
    "    top_left_date = (int(top_left[0]  + (w *4* ratio)), int(top_left[1] - (h * 2.2 * ratio)) - scaled//2)\n",
    "    # the date box could be out of bounds on the top\n",
    "    if top_left_date[1] < 0:\n",
    "        top_left_date = (top_left_date[0], 0)\n",
    "\n",
    "    bottom_right_date = (top_left_date[0] + date_width, top_left_date[1] + date_hieight)\n",
    "\n",
    "    vin_hieight = int(h * 1.3 * ratio) + scaled\n",
    "    vin_width = int(w * 5.5 * ratio) + scaled\n",
    "    \n",
    "    top_left_vin = (top_left_date[0] , int(top_left[1] - (h * 1 * ratio)) - scaled//2)\n",
    "    bottom_right_vin = (top_left_vin[0] + vin_width, top_left_vin[1] + vin_hieight)      \n",
    "        \n",
    "    sub_img_lic = img[top_left_license[1]:bottom_right_license[1], top_left_license[0]:bottom_right_license[0]]\n",
    "\n",
    "    sub_img_date = img[top_left_date[1]:bottom_right_date[1], top_left_date[0]:bottom_right_date[0]]\n",
    "\n",
    "    sub_img_vin = img[top_left_vin[1]:bottom_right_vin[1], top_left_vin[0]:bottom_right_vin[0]]\n",
    "\n",
    "    #cv.rectangle(img,top_left_license, bottom_right_license, 0,10)\n",
    "    #cv.rectangle(img,top_left_date, bottom_right_date, 0,10)\n",
    "    #cv.rectangle(img,top_left_vin, bottom_right_vin, 0,10)\n",
    "    #show_wait_destroy('Boxes of interest', img)\n",
    "    \n",
    "    return sub_img_lic, sub_img_date, sub_img_vin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_logo_scale_rotation(img):\n",
    "    \n",
    "    '''\n",
    "    finds the logo on the image, considering different scales and rotations.\n",
    "    '''\n",
    "    \n",
    "    template_hl = cv.imread('./../logos/logo_hl.png',0)\n",
    "    template_hr = cv.imread('./../logos/logo_hr.png',0)\n",
    "    template_vr = cv.imread('./../logos/logo_vr.png',0)\n",
    "    template_vl = cv.imread('./../logos/logo_vl.png',0)\n",
    "    \n",
    "    \n",
    "    # hl: image with correct rotation\n",
    "    # vr: image rotated 90 degrees clockwise\n",
    "    # vr: image rotated  90 degrees counterclockwise\n",
    "    # hr: image rotated 180 degrees\n",
    "    orientations = ('hl','hr','vr','vl')\n",
    "    templates = (template_hl, template_hr, template_vr, template_vl)\n",
    "\n",
    "    gray = img\n",
    "\n",
    "    found = None\n",
    "    \n",
    "    # loop that finds the most accurate symbol rotation in the image:\n",
    "    # in other words, loop that finds the most probable rotation of the image\n",
    "    for i in range(len(templates)):\n",
    "\n",
    "        (tH, tW) = templates[i].shape\n",
    "       \n",
    "        # loop over the scales of the image\n",
    "        for scale in np.linspace(0.2, 1.0, 5)[::-1]:\n",
    "            # resize the image according to the scale, and keep track\n",
    "            # of the ratio of the resizing\n",
    "            resized = imutils.resize(gray, width = int(gray.shape[1] * scale))\n",
    "            r = float(gray.shape[1]) / float(resized.shape[1])\n",
    "\n",
    "            # if the resized image is smaller than the template, then break\n",
    "            # from the loop\n",
    "            if resized.shape[0] < tH or resized.shape[1] < tW:\n",
    "                break\n",
    "\n",
    "            # detect edges in the resized, grayscale image and apply template\n",
    "            # matching to find the template in the image\n",
    "            \n",
    "            #works better without Canny\n",
    "            #edged = cv.Canny(resized, 50, 200)\n",
    "            edged = resized\n",
    "            result = cv.matchTemplate(edged, templates[i], cv.TM_CCOEFF_NORMED)\n",
    "            (_, maxVal, _, maxLoc) = cv.minMaxLoc(result)\n",
    "\n",
    "            # if we have found a new maximum correlation value, then update\n",
    "            # the bookkeeping variable\n",
    "            if found is None or maxVal > found[0]:\n",
    "                found = (maxVal, maxLoc, r, i)\n",
    "        \n",
    "    (maxVal, maxLoc, r, _) = found\n",
    "\n",
    "    # found[3] countains the rotation of the image\n",
    "    if orientations[found[3]] == 'vr':\n",
    "        img_lic, img_date, img_vin = find_logo_scale_rotation_v1(img, 'vr')\n",
    "\n",
    "    elif orientations[found[3]] == 'vl':\n",
    "        img_lic, img_date, img_vin = find_logo_scale_rotation_v1(img, 'vl')\n",
    "\n",
    "    elif orientations[found[3]] == 'hr':\n",
    "        img_lic, img_date, img_vin = find_logo_scale_rotation_v1(img, 'hr')\n",
    "    else:\n",
    "        img_lic, img_date, img_vin = find_logo_scale_rotation_v1(img, 'hl')\n",
    "\n",
    "    return img_lic, img_date, img_vin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_logo_scale_rotation_v1(img, orientation):\n",
    "    \n",
    "    '''\n",
    "    finds the logo on a correctedly rotated image.\n",
    "    '''\n",
    "    \n",
    "    template = cv.imread('./../logos/logo_hl.png',0)\n",
    "    \n",
    "    # flip the image, according to the most probable rotation\n",
    "    if orientation == 'vr':\n",
    "            img = cv.flip(img, 1)\n",
    "            img = cv.transpose(img)\n",
    "\n",
    "    elif orientation == 'vl':\n",
    "        img = cv.flip(img, 0)\n",
    "        img = cv.transpose(img)\n",
    "\n",
    "    elif orientation == 'hr':\n",
    "        img = cv.flip(img, -1)\n",
    "\n",
    "    gray = img\n",
    "\n",
    "    found = None\n",
    "    visualize = True\n",
    "    \n",
    "    (tH, tW) = template.shape\n",
    "    \n",
    "    # find the logo again. The bounding box coordinates and shape of the logo will be used in \n",
    "    # calculating the boxes of vin, date and license\n",
    "    \n",
    "    # loop over the scales of the image\n",
    "    for scale in np.linspace(0.2, 1.0, 5)[::-1]:\n",
    "        # resize the image according to the scale, and keep track\n",
    "        # of the ratio of the resizing\n",
    "        resized = imutils.resize(gray, width = int(gray.shape[1] * scale))\n",
    "        r = float(gray.shape[1]) / float(resized.shape[1])\n",
    "\n",
    "        # if the resized image is smaller than the template, then break\n",
    "        # from the loop\n",
    "        if resized.shape[0] < tH or resized.shape[1] < tW:\n",
    "            break\n",
    "\n",
    "        # detect edges in the resized, grayscale image and apply template\n",
    "        # matching to find the template in the image\n",
    "        #edged = cv.Canny(resized, 50, 200)\n",
    "        edged = resized\n",
    "        result = cv.matchTemplate(edged, template, cv.TM_CCOEFF_NORMED)\n",
    "        (_, maxVal, _, maxLoc) = cv.minMaxLoc(result)\n",
    "\n",
    "        # if we have found a new maximum correlation value, then update\n",
    "        # the bookkeeping variable\n",
    "        if found is None or maxVal > found[0]:\n",
    "            found = (maxVal, maxLoc, r, 0)\n",
    "                                      \n",
    "    # unpack the bookkeeping variable and compute the (x, y) coordinates\n",
    "    # of the bounding box based on the resized ratio\n",
    "    (_, maxLoc, r, _) = found\n",
    "    (startX, startY) = (int(maxLoc[0] * r), int(maxLoc[1] * r))\n",
    "    (endX, endY) = (int((maxLoc[0] + tW) * r), int((maxLoc[1] + tH) * r))\n",
    "    \n",
    "    img_lic, img_date, img_vin = find_bounding_boxes_fixed(img, (startX, startY), tW, tH, 60,ratio = r)\n",
    "\n",
    "    # draw a bounding box around the detected result and display the image\n",
    "    cv.rectangle(img, (startX, startY), (endX, endY), (0, 0, 255), 10)\n",
    "    show_wait_destroy_3d('Final Image', img)\n",
    "    return img_lic, img_date, img_vin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_orientation_threshold_rotate(img):\n",
    "    \n",
    "    '''\n",
    "    find the logo on the image, without scaling it.\n",
    "    '''\n",
    "    \n",
    "    img = find_best_angle(img)\n",
    "    #img = extract_lines(img)\n",
    "    \n",
    "    template_hl = cv.imread('./../logos/logo_hl.png',0)\n",
    "    template_hr = cv.imread('./../logos/logo_hr.png',0)\n",
    "    template_vr = cv.imread('./../logos/logo_vr.png',0)\n",
    "    template_vl = cv.imread('./../logos/logo_vl.png',0)\n",
    "    \n",
    "    orientations = ('hl','hr','vr','vl')\n",
    "    templates = (template_hl, template_hr, template_vr, template_vl)\n",
    "\n",
    "    max_matchtemplate_values = []\n",
    "    meth = 'cv.TM_CCOEFF_NORMED'\n",
    "    method = eval(meth)\n",
    "    for template in templates:\n",
    "\n",
    "        w, h = template.shape[::-1]\n",
    "        \n",
    "        # Apply template Matching fir finding the logo\n",
    "        res = cv.matchTemplate(img,template,method)\n",
    "        min_val, max_val, min_loc, max_loc = cv.minMaxLoc(res)\n",
    "        max_matchtemplate_values.append(max_val)     \n",
    "        \n",
    "    ind = max_matchtemplate_values.index(max(max_matchtemplate_values))\n",
    "\n",
    "    # if the confidence is low we are not sure to have found the logo,\n",
    "    # maybe scaling the image will help\n",
    "    if max(max_matchtemplate_values) < 0.5:\n",
    "        print('logo not found, trying with scaling')\n",
    "\n",
    "        img_lic, img_date, img_vin = find_logo_scale_rotation(img)\n",
    "    \n",
    "    else:      \n",
    "        # rotate img\n",
    "        if orientations[ind] == 'vr':\n",
    "            img = cv.flip(img, 1)\n",
    "            img = cv.transpose(img)\n",
    "            \n",
    "        elif orientations[ind] == 'vl':\n",
    "            img = cv.flip(img, 0)\n",
    "            img = cv.transpose(img)\n",
    "        \n",
    "        elif orientations[ind] == 'hr':\n",
    "            img = cv.flip(img, -1)\n",
    "    \n",
    "        # proceed with the best logo rotation and calculate bounding boxes\n",
    "        w, h = templates[0].shape[::-1]\n",
    "        res = cv.matchTemplate(img,templates[0],method)\n",
    "        threshold = 0.5\n",
    "        loc = np.where( res >= threshold)\n",
    "        print('Orientation and confidence:')\n",
    "        print(str(orientations[ind]) + ' ' + str(max_matchtemplate_values[ind]))\n",
    "        best_result = list(zip(*loc[::-1]))[0]\n",
    "        \n",
    "        cv.rectangle(img, best_result, (best_result[0] + w, best_result[1] + h), 0, 10)\n",
    "        img_lic, img_date, img_vin =  find_bounding_boxes_fixed(img, best_result, w, h)\n",
    "        \n",
    "    return img_lic, img_date, img_vin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For scans with different lighting. Not used.\n",
    "\n",
    "# def adaptive_thresholding(img):\n",
    "    \n",
    "# #     thresh1 = cv.adaptiveThreshold(img, 255, cv.ADAPTIVE_THRESH_MEAN_C, \n",
    "# #                                           cv.THRESH_BINARY, 299, 0) \n",
    "  \n",
    "#     thresh2 = cv.adaptiveThreshold(img, 255, cv.ADAPTIVE_THRESH_GAUSSIAN_C, \n",
    "#                                           cv.THRESH_BINARY, 99, 0) \n",
    "\n",
    "#     #show_wait_destroy_particular('mean', thresh1)\n",
    "#     show_wait_destroy_particular('gauss', thresh2)\n",
    "#     return thresh2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Otsu thresholding with Gaussian blur first. Not used.\n",
    "\n",
    "# def gauss_otsu_thresholding(img):\n",
    "#     blur = cv.GaussianBlur(img,(3,3),0)\n",
    "#     blur =img\n",
    "#     ret,thresh_img = cv.threshold(blur, 0, 255, cv.THRESH_BINARY + cv.THRESH_OTSU)\n",
    "\n",
    "#     show_wait_destroy_particular('gauss_otsu', thresh_img)\n",
    "#     return thresh_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filters out small connected componenets. Not used.\n",
    "\n",
    "# def remove_small_components(img):\n",
    "    \n",
    "#     img=img.astype(np.uint8) \n",
    "#     img = cv.bitwise_not(img)\n",
    "\n",
    "#     #show_wait_destroy_particular('reverse',img)\n",
    "#     #find all your connected components (white blobs in your image)\n",
    "#     nb_components, output, stats, centroids = cv.connectedComponentsWithStats(img, connectivity=8)\n",
    "    \n",
    "#     #connectedComponentswithStats yields every seperated component with information on each of them, such as size\n",
    "#     #the following part is just taking out the background which is also considered a component, but most of the time we don't want that.\n",
    "#     sizes = stats[1:, -1]; nb_components = nb_components - 1\n",
    "\n",
    "#     # minimum size of particles we want to keep (number of pixels)\n",
    "#     #here, it's a fixed value, but you can set it as you want, eg the mean of the sizes or whatever\n",
    "#     min_size = 20 \n",
    "\n",
    "#     #your answer image\n",
    "#     img2 = np.zeros((output.shape), dtype=np.uint8)\n",
    "#     #for every component in the image, you keep it only if it's above min_size\n",
    "#     for i in range(0, nb_components):\n",
    "#         if sizes[i] >= min_size:\n",
    "#             img2[output == i + 1] = 255\n",
    "\n",
    "#     #show_wait_destroy_particular('removed_particles',img2)\n",
    "#     img2 = cv.bitwise_not(img2)\n",
    "#     show_wait_destroy_particular('removed_particles_bit',img2)\n",
    "#     return img2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def morphing(img, filter_size):\n",
    "    \n",
    "    '''\n",
    "    apply a rectanglar MORPH_CLOSE filter for better shaping the characters\n",
    "    '''\n",
    "    img = cv.bitwise_not(img)\n",
    "\n",
    "    rect = cv.getStructuringElement(cv.MORPH_RECT,(filter_size,filter_size))\n",
    "    result = cv.morphologyEx(img, cv.MORPH_CLOSE, rect)\n",
    "    result = cv.bitwise_not(result)\n",
    "    show_wait_destroy_particular('Image with morphology', result)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connects together small components. Not used.\n",
    "\n",
    "# def find_if_close(cnt1,cnt2):\n",
    "#     row1,row2 = cnt1.shape[0],cnt2.shape[0]\n",
    "#     for i in range(row1):\n",
    "#         for j in range(row2):\n",
    "#             dist = np.linalg.norm(cnt1[i]-cnt2[j])\n",
    "#             if abs(dist) < 30 :\n",
    "#                 return True\n",
    "#             elif i==row1-1 and j==row2-1:\n",
    "#                 return False\n",
    "            \n",
    "# def unify_contours(img):\n",
    "#     #print('here')\n",
    "#     img = cv.bitwise_not(img)\n",
    "\n",
    "#     ret,thresh = cv.threshold(img,127,255,0)\n",
    "#     contours,hier = cv.findContours(thresh,cv.RETR_EXTERNAL,2)\n",
    "\n",
    "#     LENGTH = len(contours)\n",
    "#     status = np.zeros((LENGTH,1))\n",
    "#     #print(LENGTH)\n",
    "#     for i,cnt1 in enumerate(contours):\n",
    "#         x = i    \n",
    "#         if i != LENGTH-1:\n",
    "#             for j,cnt2 in enumerate(contours[i+1:]):\n",
    "#                 x = x+1\n",
    "#                 dist = find_if_close(cnt1,cnt2)\n",
    "#                 if dist == True:\n",
    "#                     val = min(status[i],status[x])\n",
    "#                     status[x] = status[i] = val\n",
    "#                 else:\n",
    "#                     if status[x]==status[i]:\n",
    "#                         status[x] = i+1\n",
    "\n",
    "#     unified = []\n",
    "#     maximum = int(status.max())+1\n",
    "#     for i in range(maximum):\n",
    "#         pos = np.where(status==i)[0]\n",
    "#         if pos.size != 0:\n",
    "#             cont = np.vstack(contours[i] for i in pos)\n",
    "#             hull = cv.convexHull(cont)\n",
    "#             unified.append(hull)\n",
    "\n",
    "#     cv.drawContours(img,unified,-1,(0,255,0),2)\n",
    "#     cv.drawContours(thresh,unified,-1,255,-1)\n",
    "    \n",
    "#     show_wait_destroy_particular('contours',img)\n",
    "#     show_wait_destroy_particular('contours_thresh',thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def threshold_otsu(img):\n",
    "    \n",
    "    '''\n",
    "    applies otsu thresholding to the image.\n",
    "    '''\n",
    "    show_wait_destroy_particular('Before_otsu', img)\n",
    "    gray = cv.threshold(img, 0, 255, cv.THRESH_OTSU)[1]\n",
    "    show_wait_destroy_particular('After_otsu', gray)\n",
    "    return gray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Median blurring the image. Not used.\n",
    "\n",
    "# def median_blur(img):\n",
    "#     img = cv.medianBlur(img, 5)\n",
    "#     show_wait_destroy_particular('blur', img)\n",
    "#     return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_horizontal_lines_license(img):\n",
    "    \n",
    "    '''\n",
    "    finds horizontal lines in the license bounding box, then uses them to better fdefine the bounding box.\n",
    "    ''' \n",
    "    img_gray = img\n",
    "    img_edges = cv.Canny(img_gray, 100, 100, apertureSize=3)\n",
    "    #show_wait_destroy_particular('canny', img_edges)\n",
    "    lines = cv.HoughLinesP(img_edges, 1, math.pi / 180.0, 200, minLineLength=100, maxLineGap=10)\n",
    "\n",
    "    if lines is not None:\n",
    "        #print('lines length: '+str(len(lines)))\n",
    "        angles = []\n",
    "\n",
    "        # y will never be higher than 400\n",
    "        min_y = 0\n",
    "        max_y = 501\n",
    "        img2 = img.copy()\n",
    "        mid_point = img.shape[0] //2\n",
    "        \n",
    "        # explanations in the documentation\n",
    "        for x1, y1, x2, y2 in lines[:,0]:\n",
    "            print(x1,y1,x2,y2)\n",
    "            if y1 < mid_point -5 and y1 > min_y:\n",
    "                print('new y1:' + str(y1))\n",
    "                min_y = y1\n",
    "            elif y1 > mid_point +5 and y1 < max_y:\n",
    "                max_y = y1\n",
    "            cv.line(img2, (x1, y1), (x2, y2), 0, 1)\n",
    "            angle = math.degrees(math.atan2(y2 - y1, x2 - x1))\n",
    "            angles.append(angle)\n",
    "        show_wait_destroy_particular(\"lines\", img) \n",
    "        \n",
    "#         print('Min and max and midpoint:')\n",
    "#         print(min_y, max_y, mid_point)\n",
    "#         print(img.shape)\n",
    "\n",
    "        # resize the box\n",
    "        img = img[min_y:max_y,0:img.shape[1]]\n",
    "        median_angle = np.median(angles)\n",
    "        img = ndimage.rotate(img, median_angle)\n",
    "    else:\n",
    "        print('no lines found')\n",
    "    show_wait_destroy_particular(\"After\", img) \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same as method above, but for the vin bounding box. Not used.\n",
    "\n",
    "# def find_horizontal_lines_vin(img):\n",
    "#     img_gray = img\n",
    "#     img_edges = cv.Canny(img_gray, 100, 100, apertureSize=3)\n",
    "#     #show_wait_destroy_particular('canny', img_edges)\n",
    "#     lines = cv.HoughLinesP(img_edges, 1, math.pi / 180.0, 200, minLineLength=100, maxLineGap=10)\n",
    "#     #img2 = img.copy()\n",
    "#     if lines is not None:\n",
    "#         print('lines lenghth: '+str(len(lines)))\n",
    "#         angles = []\n",
    "#         #print(lines)\n",
    "#         #print('---------')\n",
    "#         #print(lines[:,0])\n",
    "#         # y will never be higher than 400\n",
    "#         min_y = 0\n",
    "#         max_y = 501\n",
    "#         img2 = img.copy()\n",
    "#         mid_point = img.shape[0] //2\n",
    "\n",
    "#         for x1, y1, x2, y2 in lines[:,0]:\n",
    "#             print(x1,y1,x2,y2)\n",
    "#             if y1 < mid_point -10 and y1 > min_y:\n",
    "#                 print('new y1:' + str(y1))\n",
    "#                 min_y = y1\n",
    "#             elif y1 > mid_point +10 and y1 < max_y:\n",
    "#                 max_y = y1\n",
    "#             cv.line(img2, (x1, y1), (x2, y2), 0, 1)\n",
    "#             angle = math.degrees(math.atan2(y2 - y1, x2 - x1))\n",
    "#             angles.append(angle)\n",
    "#         show_wait_destroy_particular(\"lines\", img) \n",
    "#         print('Min and max and midpoint:')\n",
    "#         print(min_y, max_y, mid_point)\n",
    "#         print(img.shape)\n",
    "#         #if max_y - min_y > 40:\n",
    "#         print('cropping')\n",
    "#         img = img[min_y:max_y,0:img.shape[1]]\n",
    "#         median_angle = np.median(angles)\n",
    "#         img = ndimage.rotate(img, median_angle)\n",
    "#     else:\n",
    "#         print('no lines found')\n",
    "#     show_wait_destroy_particular(\"After\", img) \n",
    "#     return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image_license(img, COUNTER):\n",
    "    \n",
    "    '''\n",
    "    preprocessing of the license image.\n",
    "    '''\n",
    "    #img = threshold_otsu(img)\n",
    "    img = find_horizontal_lines_license(img)\n",
    "    img = morphing(img,3)\n",
    "    \n",
    "    # The images are already created in the dataset_particulars/train folder\n",
    "    #cv.imwrite(f'./../dataset_particulars/licenses/test/{COUNTER}.png', img)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image_vin(img, COUNTER):\n",
    "    \n",
    "    '''\n",
    "    preprocessing of the vin image.\n",
    "    '''\n",
    "    img = threshold_otsu(img)\n",
    "    #img = find_horizontal_lines_vin(img)\n",
    "    #img = morping(img,3)\n",
    "    \n",
    "    # The images are already created in the dataset_particulars/vin folder\n",
    "    #cv.imwrite(f'./../dataset_particulars/vins/test/{COUNTER}.png', img) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image_date(img, COUNTER):\n",
    "    \n",
    "    '''\n",
    "    preprocessing of the date image.\n",
    "    '''\n",
    "    img = threshold_otsu(img)\n",
    "    img = morphing(img,3)\n",
    "    \n",
    "    # The images are already created in the dataset_particulars/date folder\n",
    "    #cv.imwrite(f'./../dataset_particulars/dates/test/{COUNTER}.png', img) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------\n",
      "0\n",
      "Orientation and confidence:\n",
      "hl 0.7872130870819092\n",
      "0 89 571 89\n",
      "0 83 571 83\n",
      "253 75 571 75\n",
      "299 7 571 7\n",
      "new y1:7\n",
      "185 71 429 71\n",
      "363 10 571 10\n",
      "new y1:10\n",
      "391 13 539 15\n",
      "new y1:13\n",
      "33 10 165 14\n",
      "52 68 170 59\n",
      "218 9 414 9\n",
      "2 23 378 42\n",
      "new y1:23\n",
      "0 70 221 70\n",
      "44 16 285 24\n",
      "169 25 274 27\n",
      "new y1:25\n",
      "103 49 288 49\n",
      "186 58 390 65\n",
      "--------\n",
      "1\n",
      "Orientation and confidence:\n",
      "hl 0.9514100551605225\n",
      "0 66 141 68\n",
      "154 5 370 8\n",
      "new y1:5\n",
      "148 71 286 73\n",
      "140 2 392 6\n",
      "14 69 117 70\n",
      "--------\n",
      "2\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-11b9288d0cd8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0msrc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'./../dataset_cleaned_with_textcleaner/reg-cert-{i}.png'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mimg_lic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_date\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_vin\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mfind_orientation_threshold_rotate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0;31m#process_image_date(img_date, i)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-455a1122e04b>\u001b[0m in \u001b[0;36mfind_orientation_threshold_rotate\u001b[0;34m(img)\u001b[0m\n\u001b[1;32m      5\u001b[0m     '''\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_best_angle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0;31m#img = extract_lines(img)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-fa3c8d4f6e48>\u001b[0m in \u001b[0;36mfind_best_angle\u001b[0;34m(img_before)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mmedian_angle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmedian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mangles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mimg_rotated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mndimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrotate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_before\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmedian_angle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0mshow_wait_destroy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Image after deskewing\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_rotated\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;31m#print(\"Angle is {}\".format(median_angle))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/scipy/ndimage/interpolation.py\u001b[0m in \u001b[0;36mrotate\u001b[0;34m(input, angle, axes, reshape, output, order, mode, cval, prefilter)\u001b[0m\n\u001b[1;32m    736\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mndim\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    737\u001b[0m         affine_transform(input_arr, rot_matrix, offset, output_shape, output,\n\u001b[0;32m--> 738\u001b[0;31m                          order, mode, cval, prefilter)\n\u001b[0m\u001b[1;32m    739\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    740\u001b[0m         \u001b[0;31m# If ndim > 2, the rotation is applied over all the planes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/scipy/ndimage/interpolation.py\u001b[0m in \u001b[0;36maffine_transform\u001b[0;34m(input, matrix, offset, output_shape, output, order, mode, cval, prefilter)\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    485\u001b[0m         _nd_image.geometric_transform(filtered, None, None, matrix, offset,\n\u001b[0;32m--> 486\u001b[0;31m                                       output, order, mode, cval, None, None)\n\u001b[0m\u001b[1;32m    487\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "start = 0\n",
    "end = start +294\n",
    "\n",
    "# loop that processes all the images\n",
    "for i in range(start, end):\n",
    "    print('--------')\n",
    "    print(i)\n",
    "    src = cv.imread(f'./../dataset_cleaned_with_textcleaner/reg-cert-{i}.png',0)\n",
    "    img_lic, img_date, img_vin =find_orientation_threshold_rotate(src)\n",
    "    #process_image_date(img_date, i)\n",
    "    try:\n",
    "        # uncomment the one(s) you want\n",
    "        #process_image_license(img_lic, i)\n",
    "        #process_image_date(img_date, i)\n",
    "        #process_image_vin(img_vin, i)\n",
    "    except:\n",
    "        print('Error')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./../training-data-orientation.csv')\n",
    "\n",
    "licenses_true = df['license']\n",
    "plates_true = df['plate']\n",
    "\n",
    "df2 = pd.read_csv('./../results/google_results_license.csv')\n",
    "licenses_prediced = df2['license']\n",
    "plates_predicted = df2['plate']\n",
    "errors_known = df2['error']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_licenses(licenses_true, licenses_prediced, plates_true, plates_predicted, known_errors):\n",
    "    total_errors = 0\n",
    "    license_errors = 0\n",
    "    error_here = False\n",
    "    plate_errors = 0\n",
    "    unchecked_errors = 0\n",
    "    false_negatives = 0\n",
    "    \n",
    "    for i in range(len(licenses_true)):\n",
    "        error_here = False\n",
    "        if licenses_prediced[i] != licenses_true[i]:\n",
    "            error_here = True\n",
    "            license_errors +=1\n",
    "        if plates_predicted[i] != plates_true[i]:\n",
    "            error_here = True\n",
    "            plate_errors +=1\n",
    "            \n",
    "        if error_here:\n",
    "            total_errors +=1\n",
    "            if known_errors[i] == 0:\n",
    "                unchecked_errors +=1\n",
    "        else:\n",
    "            if known_errors[i] == 1:\n",
    "                false_negatives +=1\n",
    "    print('License score: ')\n",
    "    print('---------------')\n",
    "    print('License errors: ' +str(license_errors))\n",
    "    print('Plate errors: ' +str(plate_errors))\n",
    "    print('Total errors: ' +str(total_errors))\n",
    "    print('Unchecked errors: ' +str(unchecked_errors))\n",
    "    print('False positives: ' +str(false_negatives))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "License score: \n",
      "---------------\n",
      "License errors: 121\n",
      "Plate errors: 65\n",
      "Total errors: 124\n",
      "Unchecked errors: 50\n",
      "False positives: 0\n"
     ]
    }
   ],
   "source": [
    "score_licenses(licenses_true, licenses_prediced, plates_true, plates_predicted, errors_known)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "dates_true = df['registration']\n",
    "# the true dates all register a day before\n",
    "dates_true = pd.to_datetime(dates_true)\n",
    "dates_true= dates_true.apply(lambda x: x + datetime.timedelta(days=1))\n",
    "dates_true = dates_true.apply(lambda x: x.strftime('%d.%m.%Y'))\n",
    "\n",
    "df2 = pd.read_csv('./../results/google_results_date.csv')\n",
    "dates_prediced = df2['registration']\n",
    "errors_known = df2['error']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_dates(dates_true, dates_prediced, known_errors):\n",
    "    total_errors = 0\n",
    "    unchecked_errors = 0\n",
    "    false_negatives = 0\n",
    "    \n",
    "    for i in range(len(dates_true)):\n",
    "        if dates_prediced[i] != dates_true[i]:\n",
    "            total_errors +=1\n",
    "            if known_errors[i] == 0:\n",
    "                unchecked_errors +=1\n",
    "        elif known_errors[i] == 1:\n",
    "            false_negatives += 1\n",
    "            \n",
    "    print('Date score: ')\n",
    "    print('---------------')\n",
    "    print('Total errors: ' +str(total_errors))\n",
    "    print('Unchecked errors: ' +str(unchecked_errors))\n",
    "    print('False positives: ' +str(false_negatives))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date score: \n",
      "---------------\n",
      "Total errors: 161\n",
      "Unchecked errors: 113\n",
      "False positives: 0\n"
     ]
    }
   ],
   "source": [
    "score_dates(dates_true, dates_prediced, errors_known)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "vin_true = df['VIN']\n",
    "\n",
    "df2 = pd.read_csv('./../results/google_results_vin.csv')\n",
    "vin_predicted = df2['VIN']\n",
    "errors_known = df2['error']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_vins(vin_true, vin_prediced, known_errors):\n",
    "    total_errors = 0\n",
    "    unchecked_errors = 0\n",
    "    false_negatives = 0\n",
    "    \n",
    "    for i in range(len(vin_true)):\n",
    "        if vin_prediced[i] != vin_true[i]:\n",
    "            total_errors +=1\n",
    "            if known_errors[i] == 0:\n",
    "                unchecked_errors +=1\n",
    "        elif known_errors[i] == 1:\n",
    "            false_negatives += 1\n",
    "            \n",
    "    print('Vin score: ')\n",
    "    print('---------------')\n",
    "    print('Total errors: ' +str(total_errors))\n",
    "    print('Unchecked errors: ' +str(unchecked_errors))\n",
    "    print('False positives: ' +str(false_negatives))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vin score: \n",
      "---------------\n",
      "Total errors: 220\n",
      "Unchecked errors: 82\n",
      "False positives: 0\n"
     ]
    }
   ],
   "source": [
    "score_vins(vin_true, vin_predicted, errors_known)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
