{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imutils.object_detection import non_max_suppression\n",
    "import numpy as np\n",
    "import pytesseract\n",
    "import cv2\n",
    "import sys\n",
    "sys.path.append('./../template_matching')\n",
    "from clean_image import clean_noise\n",
    "from bounding_boxes_2 import find_orientation_threshold_rotate, remove_small_components, gauss_otsu_thresholding\n",
    "#from bound_box_chars import find_bbox_chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_wait_destroy_particular(winname, img):\n",
    "\n",
    "    cv2.imshow(winname, img)   \n",
    "    cv2.moveWindow(winname, 300, 0)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyWindow(winname)\n",
    "    cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_predictions(scores, geometry, min_confidence):\n",
    "    # grab the number of rows and columns from the scores volume, then\n",
    "    # initialize our set of bounding box rectangles and corresponding\n",
    "    # confidence scores\n",
    "    (numRows, numCols) = scores.shape[2:4]\n",
    "    rects = []\n",
    "    confidences = []\n",
    "\n",
    "    # loop over the number of rows\n",
    "    for y in range(0, numRows):\n",
    "        # extract the scores (probabilities), followed by the\n",
    "        # geometrical data used to derive potential bounding box\n",
    "        # coordinates that surround text\n",
    "        scoresData = scores[0, 0, y]\n",
    "        xData0 = geometry[0, 0, y]\n",
    "        xData1 = geometry[0, 1, y]\n",
    "        xData2 = geometry[0, 2, y]\n",
    "        xData3 = geometry[0, 3, y]\n",
    "        anglesData = geometry[0, 4, y]\n",
    "\n",
    "        # loop over the number of columns\n",
    "        for x in range(0, numCols):\n",
    "            # if our score does not have sufficient probability,\n",
    "            # ignore it\n",
    "            if scoresData[x] < min_confidence:\n",
    "                continue\n",
    "\n",
    "            # compute the offset factor as our resulting feature\n",
    "            # maps will be 4x smaller than the input image\n",
    "            (offsetX, offsetY) = (x * 4.0, y * 4.0)\n",
    "\n",
    "            # extract the rotation angle for the prediction and\n",
    "            # then compute the sin and cosine\n",
    "            angle = anglesData[x]\n",
    "            cos = np.cos(angle)\n",
    "            sin = np.sin(angle)\n",
    "\n",
    "            # use the geometry volume to derive the width and height\n",
    "            # of the bounding box\n",
    "            h = xData0[x] + xData2[x]\n",
    "            w = xData1[x] + xData3[x]\n",
    "\n",
    "            # compute both the starting and ending (x, y)-coordinates\n",
    "            # for the text prediction bounding box\n",
    "            endX = int(offsetX + (cos * xData1[x]) + (sin * xData2[x]))\n",
    "            endY = int(offsetY - (sin * xData1[x]) + (cos * xData2[x]))\n",
    "            startX = int(endX - w)\n",
    "            startY = int(endY - h)\n",
    "\n",
    "            # add the bounding box coordinates and probability score\n",
    "            # to our respective lists\n",
    "            rects.append((startX, startY, endX, endY))\n",
    "            confidences.append(scoresData[x])\n",
    "\n",
    "    # return a tuple of the bounding boxes and associated confidences\n",
    "    return (rects, confidences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_text(img, params):\n",
    "    min_confidence = params['min_confidence']\n",
    "    width = params['width']\n",
    "    height = params['height']\n",
    "    padding = params['padding']\n",
    "    psm = params['psm']\n",
    "    east = 'frozen_east_text_detection.pb'\n",
    "\n",
    "    image = img\n",
    "    orig = image.copy()\n",
    "    (origH, origW) = image.shape[:2]\n",
    "\n",
    "    # set the new width and height and then determine the ratio in change\n",
    "    # for both the width and height\n",
    "    (newW, newH) = (width, height)\n",
    "    rW = origW / float(newW)\n",
    "    rH = origH / float(newH)\n",
    "\n",
    "    # resize the image and grab the new image dimensions\n",
    "    image = cv2.resize(image, (newW, newH))\n",
    "    (H, W) = image.shape[:2]\n",
    "    \n",
    "    # define the two output layer names for the EAST detector model that\n",
    "    # we are interested in -- the first is the output probabilities and the\n",
    "    # second can be used to derive the bounding box coordinates of text\n",
    "    layerNames = [\n",
    "        \"feature_fusion/Conv_7/Sigmoid\",\n",
    "        \"feature_fusion/concat_3\"]\n",
    "\n",
    "    # load the pre-trained EAST text detector\n",
    "    print(\"[INFO] loading EAST text detector...\")\n",
    "    net = cv2.dnn.readNet(east)\n",
    "    \n",
    "    # construct a blob from the image and then perform a forward pass of\n",
    "    # the model to obtain the two output layer sets\n",
    "    blob = cv2.dnn.blobFromImage(image, 1.0, (W, H),\n",
    "        (0,0,0), swapRB=False, crop=True)\n",
    "    net.setInput(blob)\n",
    "    (scores, geometry) = net.forward(layerNames)\n",
    "\n",
    "    # decode the predictions, then  apply non-maxima suppression to\n",
    "    # suppress weak, overlapping bounding boxes\n",
    "    (rects, confidences) = decode_predictions(scores, geometry, min_confidence)\n",
    "    boxes = non_max_suppression(np.array(rects), probs=confidences)\n",
    "    \n",
    "    # initialize the list of results\n",
    "    results = []\n",
    "\n",
    "    # loop over the bounding boxes\n",
    "    for (startX, startY, endX, endY) in boxes:\n",
    "        # scale the bounding box coordinates based on the respective\n",
    "        # ratios\n",
    "        startX = int(startX * rW)\n",
    "        startY = int(startY * rH)\n",
    "        endX = int(endX * rW)\n",
    "        endY = int(endY * rH)\n",
    "\n",
    "        # in order to obtain a better OCR of the text we can potentially\n",
    "        # apply a bit of padding surrounding the bounding box -- here we\n",
    "        # are computing the deltas in both the x and y directions\n",
    "        dX = int((endX - startX) * padding)\n",
    "        dY = int((endY - startY) * padding)\n",
    "\n",
    "        # apply padding to each side of the bounding box, respectively\n",
    "        startX = max(0, startX - dX)\n",
    "        startY = max(0, startY - dY)\n",
    "        endX = min(origW, endX + (dX * 2))\n",
    "        endY = min(origH, endY + (dY * 2))\n",
    "\n",
    "        # extract the actual padded ROI\n",
    "        roi = orig[startY:endY, startX:endX]\n",
    "\n",
    "        # in order to apply Tesseract v4 to OCR text we must supply\n",
    "        # (1) a language, (2) an OEM flag of 1, indicating that the we\n",
    "        # wish to use the LSTM neural net model for OCR, and finally\n",
    "        # (3) an OEM value, in this case, 7 which implies that we are\n",
    "        # treating the ROI as a single line of text\n",
    "        config = (f\"-l eng --oem 1 -c tessedit_char_whitelist=01234567890ABCDEFGHIJKLMNOPQRSTUVWXYZ.* --psm {psm}\")\n",
    "        text = pytesseract.image_to_string(roi, config=config)\n",
    "\n",
    "        # add the bounding box coordinates and OCR'd text to the list\n",
    "        # of results\n",
    "        results.append(((startX, startY, endX, endY), text))\n",
    "        \n",
    "        # sort the results bounding box coordinates from top to bottom\n",
    "    results = sorted(results, key=lambda r:r[0][1])\n",
    "\n",
    "    # loop over the results\n",
    "    for ((startX, startY, endX, endY), text) in results:\n",
    "        # display the text OCR'd by Tesseract\n",
    "        print(\"OCR TEXT\")\n",
    "        print(\"========\")\n",
    "        print(\"{}\\n\".format(text))\n",
    "\n",
    "        # strip out non-ASCII text so we can draw the text on the image\n",
    "        # using OpenCV, then draw the text and a bounding box surrounding\n",
    "        # the text region of the input image\n",
    "        text = \"\".join([c if ord(c) < 128 else \"\" for c in text]).strip()\n",
    "        output = orig.copy()\n",
    "        cv2.rectangle(output, (startX, startY), (endX, endY),\n",
    "            (0, 0, 255), 2)\n",
    "        cv2.putText(output, text, (startX, startY - 20),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX, 1.2, (0, 0, 255), 3)\n",
    "\n",
    "        # show the output image\n",
    "        show_wait_destroy_particular(\"Text Detection\", output)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_3channels(img):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n",
    "    return gray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# psm\n",
    "\n",
    "#   0    Orientation and script detection (OSD) only.\n",
    "#   1    Automatic page segmentation with OSD.\n",
    "#   2    Automatic page segmentation, but no OSD, or OCR.\n",
    "#   3    Fully automatic page segmentation, but no OSD. (Default)\n",
    "#   4    Assume a single column of text of variable sizes.\n",
    "#   5    Assume a single uniform block of vertically aligned text.\n",
    "#   6    Assume a single uniform block of text.\n",
    "#   7    Treat the image as a single text line.\n",
    "#   8    Treat the image as a single word.\n",
    "#   9    Treat the image as a single word in a circle.\n",
    "#  10    Treat the image as a single character.\n",
    "#  11    Sparse text. Find as much text as possible in no particular order.\n",
    "#  12    Sparse text with OSD.\n",
    "#  13    Raw line. Treat the image as a single text line,\n",
    "# \t\t\tbypassing hacks that are Tesseract-specific."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'min_confidence' : 0.97,\n",
    "    'width' : 96*4,\n",
    "    'height' : 32*4,\n",
    "    'padding' : 0.1,\n",
    "    'psm' : 8,\n",
    "    'tessedit_write_images': True,\n",
    "    'load_system_dawg': False,\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_noise2(img):\n",
    "    #show_wait_destroy_particular('original',img)\n",
    "    img = cv2.multiply(img, 1.2)\n",
    "    img = cv2.fastNlMeansDenoising(img, None)\n",
    "    kernel = np.ones((1, 1), np.uint8)\n",
    "    img = cv2.erode(img, kernel, iterations=20)\n",
    "    #show_wait_destroy_particular('cleaned',img)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_border(img):\n",
    "    # white\n",
    "    top = int(0.2 * img.shape[0])  # shape[0] = rows\n",
    "    bottom = top\n",
    "    left = int(0.2 * img.shape[1])  # shape[1] = cols\n",
    "    right = left\n",
    "    dst = cv2.copyMakeBorder(img, top, bottom, left, right, cv2.BORDER_CONSTANT, None, 255)\n",
    "    \n",
    "    # black\n",
    "    top = int(0.05 * dst.shape[0])  # shape[0] = rows\n",
    "    bottom = top\n",
    "    left = int(0.05 * dst.shape[1])  # shape[1] = cols\n",
    "    right = left\n",
    "    dst = cv2.copyMakeBorder(dst, top, bottom, left, right, cv2.BORDER_CONSTANT, None, 0)\n",
    "    show_wait_destroy_particular('boredr',dst)\n",
    "    return dst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(img):\n",
    "    img = gauss_otsu_thresholding(img)\n",
    "    img = remove_small_components(img)\n",
    "    img = add_border(img)\n",
    "    img = convert_to_3channels(img)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3509, 2480)\n",
      "----------------------------------------\n",
      "0 Angle is 0.0\n",
      "hl 0.7613178491592407\n",
      "[INFO] loading EAST text detector...\n",
      "OCR TEXT\n",
      "========\n",
      "T0820\n",
      "\n",
      "OCR TEXT\n",
      "========\n",
      "HN\n",
      "\n",
      "[INFO] loading EAST text detector...\n",
      "OCR TEXT\n",
      "========\n",
      "EWFOAXXWPMAGBS4207\n",
      "\n",
      "OCR TEXT\n",
      "========\n",
      "BARDTY\n",
      "\n",
      "(3509, 2480)\n",
      "----------------------------------------\n",
      "1 Angle is 0.0\n",
      "hl 1.0\n",
      "[INFO] loading EAST text detector...\n",
      "OCR TEXT\n",
      "========\n",
      "TOS4O\n",
      "\n",
      "OCR TEXT\n",
      "========\n",
      "HE\n",
      "\n",
      "[INFO] loading EAST text detector...\n",
      "OCR TEXT\n",
      "========\n",
      "M1\n",
      "\n",
      "OCR TEXT\n",
      "========\n",
      "EWFOAYYWDPMACCR0R\n",
      "\n",
      "OCR TEXT\n",
      "========\n",
      "803873\n",
      "\n",
      "(3509, 2480)\n",
      "----------------------------------------\n",
      "2 Angle is -90.0\n",
      "vr 0.8407082557678223\n",
      "[INFO] loading EAST text detector...\n",
      "OCR TEXT\n",
      "========\n",
      "MX4100\n",
      "\n",
      "OCR TEXT\n",
      "========\n",
      "O\n",
      "\n",
      "[INFO] loading EAST text detector...\n",
      "OCR TEXT\n",
      "========\n",
      "WDD208Z0R1F697282\n",
      "\n",
      "OCR TEXT\n",
      "========\n",
      "STAY\n",
      "\n",
      "OCR TEXT\n",
      "========\n",
      "ETYTSSETTYEY\n",
      "\n",
      "(3509, 2480)\n",
      "----------------------------------------\n",
      "3 Angle is -90.0\n",
      "vr 0.6287045478820801\n",
      "[INFO] loading EAST text detector...\n",
      "OCR TEXT\n",
      "========\n",
      "012\n",
      "\n",
      "OCR TEXT\n",
      "========\n",
      "HM\n",
      "\n",
      "[INFO] loading EAST text detector...\n",
      "OCR TEXT\n",
      "========\n",
      "TITNTIA1\n",
      "\n",
      "OCR TEXT\n",
      "========\n",
      "AISSO031U23A\n",
      "\n",
      "(3509, 2480)\n",
      "----------------------------------------\n",
      "4 Angle is 0.0\n",
      "hl 0.5916135311126709\n",
      "[INFO] loading EAST text detector...\n",
      "OCR TEXT\n",
      "========\n",
      "CY\n",
      "\n",
      "OCR TEXT\n",
      "========\n",
      "N\n",
      "\n",
      "OCR TEXT\n",
      "========\n",
      "N1\n",
      "\n",
      "OCR TEXT\n",
      "========\n",
      "MEP\n",
      "\n",
      "[INFO] loading EAST text detector...\n",
      "OCR TEXT\n",
      "========\n",
      "31\n",
      "\n",
      "OCR TEXT\n",
      "========\n",
      "4IRINTIONR\n",
      "\n",
      "OCR TEXT\n",
      "========\n",
      "BAUZ7774\n",
      "\n"
     ]
    }
   ],
   "source": [
    "numbers = list(range(0,5))\n",
    "predictions = []\n",
    "for num in numbers:\n",
    "\n",
    "    src = cv2.imread(f'./../dataset-png-corrected/reg-cert-{num}.png', 0)\n",
    "    print(src.shape)\n",
    "    print('-'*40)\n",
    "    print(num, end=' ')\n",
    "    \n",
    "    img_lic, img_date, img_vin =find_orientation_threshold_rotate(src)\n",
    "    #print(img_lic, img_date, img_vin)\n",
    "    #convert_to_3channels(img_lic)\n",
    "    find_text(process_image(img_lic),params)\n",
    "    #find_text(convert_to_3channels(remove_small_components(gauss_otsu_thresholding(img_date))), params)\n",
    "    find_text(process_image(img_vin), params)\n",
    "    \n",
    "    #img = cv2.fastNlMeansDenoising(img_lic, None)\n",
    "    #show_wait_destroy_particular('aa',img)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
